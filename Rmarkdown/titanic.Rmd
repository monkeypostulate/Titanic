---
title: "Titanic"
author: ""
date: " "
output: 
  html_document:
      css: src/css_style.css
      toc: true # table of content true
      number_sections: true  ## if you want number sections at each table heade
      code_folding: hide #show


---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<script src="src/google-analytics.js"></script>
<script src="src/interactive.js"></script>

# Titanic challenge
 


The sinking of the  Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. 

One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.

In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.



## Executive Summary

<br>

![Figure 1:](images\objectives.png)


```{r message=FALSE}
# Load libraries
library(tidyverse) # Data manipulation
library(mlr)
library(rpart) # Decision Tree
library(rpart.plot)  # Plot Decision tree
library(randomForest) # Random forest algorithm
library(ggplot2) # Visualization
library(plotly) # Interactive visualizations
set.seed(21) # Specify Seed (Usuful for replications)

library(kableExtra)
```




# Data

```{r echo=FALSE}

perf.measures<-read.csv('../performance_measures.csv', sep=';')

```



## Data Extraction
<br> <br>
Let's load the titanic data using the function **read.csv()**.
The titanic dataset is stored  as a csv file, and it is in the subfolder titanic.
*Click the button code to see the R-code.*

<div class="Code">
```{r  echo=TRUE}
# Load datasets
titanic.dataset<-read.csv('titanic\\train.csv') 
```
</div>





## Data Exploration
<br> <br>

There are 10 attributes: 

* **Name:** Passenger’s name, 
* **Sex:** Passenger’s sex, 
* **Age:** Passenger’s age, 
* **SibSp:** Number of siblings/spouses aboard, 
* **Parch:** Number of parents/children aboard, 
* **Pclass:** Passenger’s class, 
* **Ticket:** Ticket number, 
* **Fare:** Fare, 
* **Cabin:** Cabin, 
* **Embarked:** Port of embarkation,
* **Survived:** Survived (1) or died (0).



pclass: A proxy for socio-economic status (SES)
1st = Upper
2nd = Middle
3rd = Lower

Age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5

SibSp: The dataset defines family relations in this way...
Sibling = brother, sister, stepbrother, stepsister
Spouse = husband, wife (mistresses and fiancés were ignored)

Parch: The dataset defines family relations in this way...
Parent = mother, father
Child = daughter, son, stepdaughter, stepson
Some children travelled only with a nanny, therefore parch=0 for them.



```{r}
 options(knitr.kable.NA = '')
titanic.dataset%>%
  select(-c(PassengerId,Name,Ticket))%>%  # Remove columns from summary
  summary()%>% # The function is useful to get quick description of the data
  knitr::kable(digits=2 )%>% # Create table in HTML
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))%>% # Style
  row_spec(0, bold = T, color = "white", background = "#4056A1")

```

We format the tables using the package <a href="https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html"> knitr </a>.


Let's have a lock at the top 3 rows using the function **head()**. 

```{r }
titanic.dataset%>%
  select(-c(PassengerId,Ticket))%>%
  head(3)%>%
  kable()%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))%>% 
  row_spec(0, bold = T, color = "white", background = "#4056A1")
```

<br> <br>

## Visualizations
<br> <br>

How you visualize a variable depends on whether the variable is categorical or continous. 
What makes a chart effective is the depth of a critical analysis displayed.  
In other words, do you have information worth making a chart for? and have you portrayed it accuretely?
There 4 steps to create an effective chart^[If you would like to learn the DOS and DON'TS of presenting figures, I recommend you the book *The Wall Street Journal Guide to Information Graphics: The Dos and Don'ts of Presenting Data, Facts, and Figures by Dona M. Wong*.].

* **Research**: 
* **Edit:** identify key message, make numerical adjustemt to enhance your point.
* **Plot:**  choose the right plot to present your findings and settings (scale, baseline). 
* **Review:** check your plot against your sources.



<button  onclick="plusDivs(-1)"  class="btn">&#10094; Plot</button>
<button  onclick="plusDivs(1)"  class="btn">Plot &#10095;</button>
  

<div class="plots">
<br>
Let's look at the age distribution of those passangers who survived and those who didn't. 
The plot below shows that the survival chances of children are relatively high.




```{r warning=FALSE}

col1<-c('0'='#E8A87C','1'='#85CDCA')

g<-titanic.dataset%>%
  ggplot()+
  geom_density(aes(x=Age,fill=factor(Survived)),alpha=0.7)+
  scale_fill_manual('Survive',values=col1)+
  theme_classic()+ 
  ylab('Density') # Convert ggplot to  an interctive plot with plotly
ggplotly(g)

```

</div>


<div class='plots' style="display: none">

We can plot the distribution of categorical variables using bar charts.

```{r}

col1<-c('0'='#E8A87C','1'='#85CDCA')

g<-titanic.dataset%>%
  group_by(Pclass,Survived=factor(Survived))%>%
  summarise(Total=dplyr::n())%>%
  ggplot()+
  geom_bar(aes(x=Pclass,y=Total,fill=Survived),
           stat='identity', position='fill')+
  scale_fill_manual('Survive',values=col1)+
  theme_classic()+xlab('Pclass')+
  ylab('')
# Convert ggplot to  an interctive plot with plotly
ggplotly(g)
```


<a href="https://ggplot2.tidyverse.org/reference/geom_bar.html" target="blank">
Source</a>
</div>


<div class="plots" style="display: none">

An alternative to display the distribtuion broken down by a categorical variable is the *boxplot*. A boxplot makes it easier to compare distributions,

```{r warning=FALSE}
col1<-c('0'='#E8A87C','1'='#85CDCA')

g<-titanic.dataset%>%
  mutate(Pclass=factor(Pclass))%>%
  ggplot()+
  geom_boxplot(aes(Pclass,Age), fill='#E8A87C', color='#85CDCA')+
  theme_classic()
# Convert ggplot to  an interctive plot with plotly
ggplotly(g)
```
<a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html" target="blank"> Source </a>
</div>

The interactive plots are done using the library **plotly**. 
The advantage of creating interactive plots with plotly and ggptlot are twofold.
First, you create a ggplot which can be saved as png, pdf, etc., and you can use this plots in powerpoint presentations, add them in word documents. If you want to save your ggplot as pdf, you replace the command *ggplotly(g)* with **ggsave(g)**.
Second, creating an interactive plot after using ggplot requires one function **ggplotly()**.
If you would like to learn more about plotly, visit the following 
<a href="https://plot.ly/r/" target="blank"> page</a>.
 
<br>
<br>

## Data Cleaning
<br> <br>
The process of detecting and correcting (or removing) corrupt or inaccurate records from a record set, table, or database and refers to identifying incomplete, incorrect, inaccurate or irrelevant parts of the data and then replacing, modifying, or deleting the dirty or coarse data. Data cleansing may be performed interactively with data wrangling tools, or as batch processing through scripting.

## Filling Missing Values techniques:
<br> <br>
Several Machine Learning algorithms do not work with missing values.
These are a some techniques to handle missing values: 

* Do nothing.
* Remove observations with missing values (raws and/or columns)
* Imputation Using (Mean/Median) Values.
* Advantage:  easy and fast.
* Disadvantage: it doesn’t consider the correlations between features.
* Imputation Using (Most Frequent) or (Zero/Constant) Values.
* Imputation Using Deep Learning.
* Imputation Using k-NN.

Our choice is **imputation using Mean**.
```{r}
# Calculate Average age
m.Age<-mean(titanic.dataset$Age,na.rm=T) 

titanic.dataset<-titanic.dataset%>%
  mutate(Age=replace_na(Age,m.Age)) 

```
If you would like to know more about using k-NN for data imputations, here are a few references: <a href="https://towardsdatascience.com/the-use-of-knn-for-missing-values-cf33d935c637" target="blank">The use of KNN for missing values</a>.



## Split data into train and test data
<br> <br>
![Figure 2: ](images\traintestdata.png)


```{r}
# ##################################
# Create Train and Test data

titanic.dataset$id<-1:dim(titanic.dataset)[1]

# Randomize data: Create train and test dataset
train.sample <- sample(x=1:dim(titanic.dataset)[1],
                       size=floor(dim(titanic.dataset)[1]*0.75), # Train data consists of 75% of the dataset
                       replace=F)

titanic.train<-titanic.dataset%>%
  filter(id %in%train.sample)
titanic.test<-titanic.dataset%>%
  filter(!(id %in%train.sample))
```
## Feature selection:
<br> <br>
```{r }
# Variables used in the model
columns<-c('Pclass','Sex','Age','SibSp','Parch','Fare','Embarked','Survived')
titanic.train<-titanic.dataset[,columns]
titanic.test<-titanic.test[,columns]
```

# Model
<br> <br>

## Machine Learning Algorithms
<br> <br>
![Figure 3:](images\models.png)



## Decision Tree
<br> <br>
Decision trees partition the feature space into a set of rectangles, and then fit a simple model in each one (e.g. a costant).  A decision tree is a tree whose inner nodes represen features. Each edge stands for an feature value, and each leaf node is given a class value (i.e. a constant).
Decision trees are fairly intuitive and their predictions are easy to interpret. 



<button  onclick="plusDivs3(-1)"  class="btn">&#10094;Tree</button>
<button  onclick="plusDivs3(1)"  class="btn">Tree &#10095;</button>
  

<div class="decision_tree">
![Figure: ](images/tree.png)
</div>

<div class="decision_tree" style="display:none">
```{r}
chosen.model<-'classif.rpart'
classifi.model<-makeClassifTask(id='titanic',
                                data=titanic.train,
                                target='Survived')

chosen.learner<-makeLearner(chosen.model,
                            predict.type = "prob",
                            par.vals = list())


train.model<-mlr::train(learner=chosen.learner,
                     task=classifi.model)

pred.classif<-predict(train.model,
                         newdata =titanic.test)

dt.model<-getLearnerModel(train.model)

rpart.plot(getLearnerModel(train.model),roundint=FALSE)
```
</div>

<div class="decision_tree" style="display: none">


### Variable Importance


```{r}
var.importance<-data.frame('Variable'=names(dt.model$variable.importance),
           'Importance'=dt.model$variable.importance)

dt.varimport<-var.importance%>%
  ggplot()+
  geom_bar(aes(x=reorder(Variable,Importance),y=Importance),
           stat='identity',
           fill='#F13C20')+
  coord_flip()+
  theme_classic()+
  xlab('Variable Importance')+
  ylab('Variable')


ggplotly(dt.varimport)
```

</div>

```{r echo=FALSE}
# ##################################
# Model Performance
# ##################################
#conf.mat<-
#  calculateConfusionMatrix(pred.classif, relative = TRUE)


#perf<-performance(pred.classif, measures =chosen.measures,
#                  model=train.model)

```

<br>  <br>

## Random Forest
<br> <br>

A random forest is an ensembe of decision trees trained via the boostraping aggregating method (bagging).
With random forest, we get a diverse of classifier by training decision trees on different random subsets of the training dataset. When sampling is performed with replacement, the methid is called *bagging*. When the sampling is performed without replacement, it is called pasting.
The motivation
Once all predictors are trained, the ensembe can make a predictions for a new data point by aggregating the predictions of all predictors.
Generally, a random forest has a lower variance than a single decision tree trained on the original training dataset.


We decide to use the random forest since it is not too slow compare to Adaboosting and Neural Networks, and it has a good performance (good Accuracy, Precision and sensitivity).


![Figure 4:](images\RF.png)


```{r }
# Model: Random Forest
chosen.learner<-'classif.randomForest'


```



## Tune Model
<br> <br>
Almost all machine learning algorithms have hyperparameters, specifications to control the algorithm's performance.
The values of the hyperparameters are not adapted by the training algorithm itselt.
The hyperparameters cannot simply be learned with the training set, since it would always choose the most complex models and it would result in overfitting. 
To solve this proble, we need a validation set of examples that the training algorithm does not observe.


```{r}
# ##################################
# Hyper parameters
discrete_ps = makeParamSet(
  makeDiscreteParam("ntree",
                    values =c(1,5)),
  makeDiscreteParam("mtry",
                    values =c(1,2))
  )

```


### Cross validation (K-fold)
<br>  <br>
Cross validation is a widely used method for estimating prediction error. 
Ideally, if we have enoguh  data, we would set aside a validation set and use it to assess the performance of our prediction model.
The K-fold cross validation uses part of the train data to fit the model, and a different part to test it.
We split the data into K equal-sized parts.
We fit train the model with K-1 parts and test it with the kth part of the data.
We do this for $k\in \{1,...,K\}$, and combine the K estimates of prediction error.


![Figure 6:](images\RandomForest.png)



```{r }
# ##################################
# Cross validation: 10 fold.
  rdesc<-makeResampleDesc(method="CV",
                          iters = 10, # Our K-fold equals 10-fold
                          predict = 'test')

  ctrl<-makeTuneControlGrid()
```  
An alernative to 10-fold is one-leave out. However, since the dataset is not small, the one-leavel out is computational expensive.






```{r }
  chosen.model<-  'classif.randomForest'
  chosen.learner<-makeLearner(chosen.model,
                              predict.type = "prob",
                              par.vals = list())

```



### Optimal Model
```{r message=FALSE, warning=FALSE}
  optimal.rf<-tuneParams(chosen.learner, task = classifi.model, resampling =
                    rdesc,
                  par.set = discrete_ps, control=ctrl,
                  measures = list(acc,mmce,timetrain,f1,logloss)) # measures to be calculated
  
cv.output = generateHyperParsEffectData(optimal.rf)
```


#### Train Model
```{r message=FALSE,warning=FALSE}
## #######################################
# Get Optimal mode#
# ########################################
chosen.learner<-makeLearner(chosen.model,
                            predict.type = "prob",
                            par.vals = list(ntree=optimal.rf$x$ntree,
                                            mtry=optimal.rf$x$mtry))

train.model<-mlr::train(learner=chosen.learner,
                        task=classifi.model)


```


## Model Performance
<br> <br>
```{r , echo=FALSE}
names(perf.measures)<-c('R name','Name','Description')

perf.measures[1:10,]%>%
kable%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))%>% # Style
  row_spec(0, bold = T, color = "white", background = "#4056A1")
```




```{r}
# ##################################
# Predictions (with optimal model)
pred.classif<-predict(train.model,
                      newdata =titanic.test)
# Performance Measures
chosen.measures<-list(acc,mmce,ppv,
                      tpr,f1,gpr,
                      auc,logloss,timetrain)

best.model.per<-performance(pred.classif, measures =chosen.measures,
            model=train.model)



```

<a href="https://mlr.mlr-org.com/articles/tutorial/measures.html#general-performance-measures" target="blank"> Performance Measures </a>



<button  onclick="plusDivs2(-1)"  class="btn">&#10094; Measure</button>
<button  onclick="plusDivs2(1)"  class="btn">Measure &#10095;</button>
  


<div class="model_performance" style="display: none">
### Confusion Matrix

</div>


<div class="model_performance" style="display: none">
### Precision vs Sensitivity

```{r }

perf.data<-generateThreshVsPerfData(pred.classif, list(fpr,ppv, tpr))

col<-c('Precision'='#85CDCA','Sensitivity'='#E8A87C')

g<-perf.data$data%>%
      ggplot()+
      geom_line(aes(x=threshold,y=ppv,col='Precision'), lwd=1.1)+
      geom_line(aes(x=threshold,y=tpr,col='Sensitivity'), lwd=1.1)+
      theme_classic()+
      xlab('Threshold')+ylab('')+ggtitle('Precision & Sensitivity')+
      scale_color_manual(values=col,'')+
      scale_linetype_manual(values=c('solid','dashed'),'Measure')

ggplotly(g)

```
</div>



<div class="model_performance">
### ROC-curve
The ROC  (Receiver operating characteristic) curve is a common plot used for binary classifiers. 
In the ROC curve, the sensitivity against 1-specificity.

At point $(0,0)$ the random forest algorithm predicts that all passangers will not survive. 
While in the other extreme $(1,1)$, the random forest predicts that all passangers survives.
The ideal machine learning algorithm would have a curve which consists only of the point (0,1), and thus has $100\%$ specifity and $100\%$ sensitivity.


```{r}
col<-c('Random Forest'='#C38D9E')

roc.plot<-perf.data$data%>%
      ggplot()+
      geom_line(aes(x=fpr,y=tpr,col='Random Forest'), cex=1.2)+
      xlab('False positive rate')+ylab('True positive rate')+
      ggtitle('ROC curve')+theme_classic()+
        scale_color_manual(values=col,'')+
  geom_abline(intercept=0,slope=1)

  ggplotly(roc.plot)
```

<a href='https://mlr.mlr-org.com/articles/tutorial/roc_analysis.html' target="blank"> ROC curve  </a>

</div>


## Simulations


# References

